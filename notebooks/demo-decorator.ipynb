{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the current working directory as a Path object\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# Get the parent directory of the current directory\n",
    "parent_dir = current_dir.parent\n",
    "\n",
    "# Add the parent directory to sys.path if it's not already there\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.append(str(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "from PyDyTuesday import get_date\n",
    "\n",
    "from src.capture_data import capture_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUESDAY_DATE = \"2025-02-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agencies.csv downloaded\n",
      "crime_data_explorer_page.png downloaded\n",
      "meta.yaml downloaded\n",
      "readme.md downloaded\n"
     ]
    }
   ],
   "source": [
    "get_date(TUESDAY_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_date_dec = capture_data(\n",
    "    output_dir=\".\",\n",
    "    dbpath=\"fbi_crime.ddb\",\n",
    "    data_table_name=\"crime_data\",\n",
    "    metadata_table_name=\"crime_metadata\",\n",
    "    file_info_table_name=\"crime_file_info\",\n",
    "    image_table_name=\"crime_images\")(get_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def explore_database(conn):\n",
    "#     # 1. List all tables\n",
    "#     print(\"Tables in the database:\")\n",
    "#     tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall()\n",
    "#     for table in tables:\n",
    "#         print(table[0])\n",
    "#     print()\n",
    "\n",
    "#     # 2. Show schema of crime_data table\n",
    "#     print(\"Schema of crime_data table:\")\n",
    "#     schema = conn.execute(\"DESCRIBE crime_data\").fetchall()\n",
    "#     for column in schema:\n",
    "#         print(f\"{column[0]}: {column[1]}\")\n",
    "#     print()\n",
    "\n",
    "#     # 3. Count rows in crime_data table\n",
    "#     row_count = conn.execute(\"SELECT COUNT(*) FROM crime_data\").fetchone()[0]\n",
    "#     print(f\"Number of rows in crime_data table: {row_count}\")\n",
    "#     print()\n",
    "\n",
    "#     # 4. Show first 5 rows of crime_data\n",
    "#     print(\"First 5 rows of crime_data:\")\n",
    "#     data = conn.execute(\"SELECT * FROM crime_data LIMIT 5\").fetchall()\n",
    "#     for row in data:\n",
    "#         print(row)\n",
    "#     print()\n",
    "\n",
    "#     # 5. Show metadata\n",
    "#     print(\"Metadata:\")\n",
    "#     metadata = conn.execute(\"SELECT * FROM crime_metadata\").fetchall()\n",
    "#     for row in metadata:\n",
    "#         print(f\"{row[0]}: {row[1]}\")\n",
    "#     print()\n",
    "\n",
    "#     # 6. List files in file_info table\n",
    "#     print(\"Files processed:\")\n",
    "#     files = conn.execute(\"SELECT file_type, file_name, upload_date FROM crime_file_info\").fetchall()\n",
    "#     for file in files:\n",
    "#         print(f\"Type: {file[0]}, Name: {file[1]}, Uploaded: {file[2]}\")\n",
    "#     print()\n",
    "\n",
    "#     # 7. Check if image data is stored\n",
    "#     image_count = conn.execute(\"SELECT COUNT(*) FROM crime_images\").fetchone()[0]\n",
    "#     print(f\"Number of images stored: {image_count}\")\n",
    "#     print()\n",
    "\n",
    "#     # 8. Show README content\n",
    "#     readme_content = conn.execute(\"SELECT file_content FROM crime_file_info WHERE file_type = 'readme'\").fetchone()\n",
    "#     if readme_content:\n",
    "#         print(\"README Content:\")\n",
    "#         print(readme_content[0][:500] + \"...\") # Print first 500 characters\n",
    "#     else:\n",
    "#         print(\"README not found\")\n",
    "\n",
    "# # Usage\n",
    "# explore_database(conn)\n",
    "\n",
    "# # Don't forget to close the connection when done\n",
    "# conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-20 15:55:02.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.capture_data\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mStarting function 'get_date' with asat_date=2025-02-18, args=(), kwargs={}\u001b[0m\n",
      "\u001b[32m2025-02-20 15:55:02.250\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.capture_data\u001b[0m:\u001b[36mvalidate_and_parse_date\u001b[0m:\u001b[36m151\u001b[0m - \u001b[34m\u001b[1mParsed date successfully: 2025-02-18 00:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agencies.csv downloaded\n",
      "crime_data_explorer_page.png downloaded\n",
      "meta.yaml downloaded\n",
      "readme.md downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-20 15:56:02.959\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36msrc.capture_data\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m53\u001b[0m - \u001b[31m\u001b[1mTimeout waiting for files. Found: []\u001b[0m\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "Timeout waiting for files. Found: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_date_dec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTUESDAY_DATE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/github/databooth/tidy-tuesdays/src/capture_data.py:54\u001b[0m, in \u001b[0;36mcapture_data.<locals>.decorator.<locals>.wrapper\u001b[0;34m(asat_date, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         error_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimeout waiting for files. Found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[f\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mf\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mnew_files]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(error_msg)\n\u001b[0;32m---> 54\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(error_msg)\n\u001b[1;32m     56\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Wait for 1 second before checking again\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Prepare output directory\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: Timeout waiting for files. Found: []"
     ]
    }
   ],
   "source": [
    "get_date_dec(TUESDAY_DATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
